{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKv/MtoZ5A3P7+BQ8EdqL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGkurnia/sentiment/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nama : Derfansyah Guswiranata Kurnia\n",
        "- Iddicoding: dgkurnia\n",
        "- email dicoding: weerakurnia@gmai.com"
      ],
      "metadata": {
        "id": "ZFgY-GaMMUMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Insiasi"
      ],
      "metadata": {
        "id": "I67moXBB9Kl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perpustakaan tahap awal\n",
        "!pip install selenium beautifulsoup4 pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e3E8nEu9HDC",
        "outputId": "b81f7eb4-18a6-48bb-952e-337227c58670"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.27.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Impor Bagian awal\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "#modifikasi percepatan\n",
        "import asyncio\n",
        "import aiohttp\n",
        "from concurrent.futures import ProcessPoolExecutor"
      ],
      "metadata": {
        "id": "G0JFUIhxA7w8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nxlN2zGP8_fz"
      },
      "outputs": [],
      "source": [
        "#Next Import\n",
        "import datetime as dt  # Manipulasi data waktu dan tanggal\n",
        "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
        "import string  # Berisi konstanta string, seperti tanda baca\n",
        "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
        "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tambahan\n",
        "from selenium.webdriver.chrome.service import Service"
      ],
      "metadata": {
        "id": "Att_8AttiFq3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sastrawi"
      ],
      "metadata": {
        "id": "CthS3NbTETmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalasi sastrawi\n",
        "!pip install sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmP2sjmKgLXm",
        "outputId": "d636acbd-3e66-4002-d5c4-5b7d2ba1af2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/209.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Impor Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
        "#ke wordcloud"
      ],
      "metadata": {
        "id": "Cwad-u4jgN6b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seksi wordcloud\n",
        "!pip install wordcloud\n",
        "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks\n",
        "# ke NITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iaIjWrHHPiA",
        "outputId": "1b25dc99-31e3-4a60-b473-ff47970a270a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NITK\n",
        "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
        "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
        "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stopwords) dalam berbagai bahasa."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4LADjm8gWcQ",
        "outputId": "a0063266-76fd-4770-e7b1-965d7d3849c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#impor file tambahan (google drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_1qYPLME9l8",
        "outputId": "c4212720-a2f4-4fa7-8b89-a7903c180eb4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perpustakaan lain untuk analisis"
      ],
      "metadata": {
        "id": "rFOBGavtLc-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Seksi Io dan lain-lain\n",
        "import os\n",
        "from io import StringIO\n",
        "import concurrent.futures #untuk pemrograman paralel\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "OJwYodA9Msss"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Interpolasi untuk perbaikan: Grafik\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "#perpustakaan untuk interpolasi\n",
        "from scipy.interpolate import interp1d"
      ],
      "metadata": {
        "id": "1F5B6x4IGCU4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian lain\n",
        "import csv\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "fjfVZi3GLg35"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persiapan untuk analisis"
      ],
      "metadata": {
        "id": "E98qlEH4M1DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pandas\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "d_YCBQfMmhQo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ekstraksi\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer  #sentimen\n",
        "#pemisahan\n",
        "from sklearn.model_selection import train_test_split as ttsplit\n",
        "#ke klasifikasi"
      ],
      "metadata": {
        "id": "YX0Ag2T7MzVc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#klasifikasi randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier as rfclasifi #teknik 'randomfprest'\n",
        "from sklearn.tree import DecisionTreeClassifier #teknik 'keputusan'\n",
        "from sklearn.svm import SVC #teknik SVC\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "piG-cutDNUEt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pengambilan ulasan dari situs Tokopedia"
      ],
      "metadata": {
        "id": "xWr5-V4thU5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap awal pengambilan\n",
        "urllist = [\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-jazlyn-black-jazlyn-black-s/review\",\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-gribson-rayon-navy-s/review\",\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-lavrenti-white-lavrenti-white-s/review\"\n",
        "]"
      ],
      "metadata": {
        "id": "kJea43wQk49U"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ada tiga ulasan yang dipakai untuk analisis"
      ],
      "metadata": {
        "id": "louZK_TEEtni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan untuk proses pengambilan list: Tahap Extraksi HTM secara asinkronus\n",
        "async def fetch_html(url):\n",
        "    loop = asyncio.get_event_loop()\n",
        "    response = await loop.run_in_executor(None, requests.get, url)\n",
        "    return response.content\n",
        "\n",
        "# Fungsi ekstraksi secara asinkronus\n",
        "async def review_scrapper(url):\n",
        "    html_content = await fetch_html(url)\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Ekstraksi ulasan\n",
        "    ulasan = []\n",
        "    for rev in soup.find_all('div', class_='review-class'):\n",
        "        teks = rev.find('div', class_='review-content').text.strip()\n",
        "        ulasan.append(teks)\n",
        "\n",
        "    return ulasan\n",
        "#ke potongan"
      ],
      "metadata": {
        "id": "_4GeAo7aGbx3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan asinkronus untuk pemrosesan url\n",
        "def process_urls(chunk):\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "\n",
        "    # Gather results from the asynchronous review scrapper\n",
        "    tasks = [review_scrapper(url) for url in chunk]\n",
        "    results = loop.run_until_complete(asyncio.gather(*tasks))\n",
        "\n",
        "    # Flatten the list of results\n",
        "    return [item for sublist in results for item in sublist]\n",
        "#ke fungsi utama"
      ],
      "metadata": {
        "id": "hg4DuheqmD82"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pengambilan nilai ulasan per potongan"
      ],
      "metadata": {
        "id": "alUWazR_J4vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fungsi pemotongan analisis\n",
        "def chunk_and_execute(urls, chunk_size=10, output_prefix='intermediate_reviews'):\n",
        "    totulas = []\n",
        "\n",
        "    # Inspeksi intermediet\n",
        "    existing_files = [f for f in os.listdir() if f.startswith(output_prefix) and f.endswith('.csv')]\n",
        "    last_processed_index = len(existing_files) - 1 if existing_files else -1\n",
        "\n",
        "    # Mulai dari titik persimpanan terbaru\n",
        "    for i in range(last_processed_index + 1):\n",
        "        df = pd.read_csv(f'{output_prefix}{i}.csv')\n",
        "        totulas.extend(df['Review'].tolist())\n",
        "\n",
        "    # Start processing from the next chunk\n",
        "    num_chunks = (len(urls) + chunk_size - 1) // chunk_size  # Ceiling division\n",
        "\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        for i in range(last_processed_index + 1, num_chunks):\n",
        "            start_idx = i * chunk_size\n",
        "            end_idx = min((i + 1) * chunk_size, len(urls))\n",
        "\n",
        "            chunk_url_list = urls[start_idx:end_idx]\n",
        "\n",
        "            # Process the current chunk of URLs using multiprocessing\n",
        "            results = executor.submit(process_urls, chunk_url_list).result()\n",
        "\n",
        "            # Extend the main list with scraped data\n",
        "            totulas.extend(results)\n",
        "\n",
        "            # Save intermediate results to CSV\n",
        "            pd.DataFrame(totulas[:], columns=['Review']).to_csv(f'{output_prefix}{i}.csv', index=False)\n",
        "\n",
        "    return totulas\n",
        "#ke tahap akhir"
      ],
      "metadata": {
        "id": "roVHgmd2JMl1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#penyatuan ke hasil akhir\n",
        "hslakhir = chunk_and_execute(urllist)\n",
        "#ke penyetelan data csv"
      ],
      "metadata": {
        "id": "YdXlCUiDrO6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "totulas adalah **'total ulasan'** yang dipakai untuk analisis hasi akhir **(hslakhir)**"
      ],
      "metadata": {
        "id": "zkt3ypzVJ2Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan df untuk pembersihan\n",
        "dfori = pd.DataFrame(hslakhir, columns=['Review'])\n",
        "dfkopi = dfori.copy() #Jangan pakai data asli\n",
        "dfkopi.to_csv('tokopedia_reviews.csv', index=False)"
      ],
      "metadata": {
        "id": "wi0e2dg7KS1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data yang dipakai adala **'dfkopi'**"
      ],
      "metadata": {
        "id": "AGWfNanE574Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi dataset\n",
        "dfinfo = dfkopi.info()\n",
        "print(dfinfo)"
      ],
      "metadata": {
        "id": "tQkvoQdAK7y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tahap awal (pembersihan)"
      ],
      "metadata": {
        "id": "yd95Hc1KJktQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan untuk pembersihan\n"
      ],
      "metadata": {
        "id": "JNP_5d9vJjtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan tahap awal\n"
      ],
      "metadata": {
        "id": "NDIgOYfQIPdx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}