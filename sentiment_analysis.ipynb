{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyN8RWev1ZrTIeDBbga5gV4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGkurnia/sentiment/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nama : Derfansyah Guswiranata Kurnia\n",
        "- Iddicoding: dgkurnia\n",
        "- email dicoding: weerakurnia@gmai.com"
      ],
      "metadata": {
        "id": "ZFgY-GaMMUMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Insiasi"
      ],
      "metadata": {
        "id": "I67moXBB9Kl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perbaikan untuk upgrade colab\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "id": "-CYGcVahE4xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perpustakaan tahap awal\n",
        "!pip install selenium beautifulsoup4 pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e3E8nEu9HDC",
        "outputId": "8565f752-ac4e-492f-e758-7ecab2c0cffb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.28.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Impor Bagian awal\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "G0JFUIhxA7w8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nxlN2zGP8_fz"
      },
      "outputs": [],
      "source": [
        "#Next Import\n",
        "import datetime as dt  # Manipulasi data waktu dan tanggal\n",
        "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
        "import string  # Berisi konstanta string, seperti tanda baca\n",
        "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
        "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tambahan\n",
        "from selenium.webdriver.chrome.service import Service"
      ],
      "metadata": {
        "id": "Att_8AttiFq3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalasi sastrawi\n",
        "!pip install sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmP2sjmKgLXm",
        "outputId": "705c0044-a47a-440a-e333-09f42e49ed1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/209.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Impor Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
        "#ke wordcloud"
      ],
      "metadata": {
        "id": "Cwad-u4jgN6b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seksi wordcloud\n",
        "!pip install wordcloud\n",
        "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks\n",
        "# ke NITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iaIjWrHHPiA",
        "outputId": "4ed47b75-0367-4837-bdb3-18bcbe4c676c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordcloud\n",
            "  Downloading wordcloud-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Downloading wordcloud-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/511.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/511.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m501.8/511.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.1/511.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wordcloud\n",
            "Successfully installed wordcloud-1.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NITK\n",
        "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
        "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
        "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stopwords) dalam berbagai bahasa."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4LADjm8gWcQ",
        "outputId": "b059090f-7852-4316-a219-e1967c821492"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#impor file tambahan (google drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_1qYPLME9l8",
        "outputId": "e4439dd8-6703-4968-c600-e82bf17c7ff4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perpustakaan lain untuk analisis"
      ],
      "metadata": {
        "id": "rFOBGavtLc-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Seksi Io dan lain-lain\n",
        "from io import StringIO\n",
        "import concurrent.futures #untuk pemrograman paralel\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "OJwYodA9Msss"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Interpolasi untuk perbaikan: Grafik\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime as dt\n",
        "#perpustakaan untuk interpolasi\n",
        "from scipy.interpolate import interp1d"
      ],
      "metadata": {
        "id": "1F5B6x4IGCU4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian lain\n",
        "import csv\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "fjfVZi3GLg35"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persiapan untuk analisis"
      ],
      "metadata": {
        "id": "E98qlEH4M1DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ekstraksi\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer  #sentimen\n",
        "#pemisahan\n",
        "from sklearn.model_selection import train_test_split as ttsplit\n",
        "#ke klasifikasi"
      ],
      "metadata": {
        "id": "YX0Ag2T7MzVc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#klasifikasi randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier as rfclasifi #teknik 'randomfprest'\n",
        "from sklearn.tree import DecisionTreeClassifier #teknik 'keputusan'\n",
        "from sklearn.svm import SVC #teknik SVC\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "piG-cutDNUEt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pengambilan ulasan dari situs Tokopedia"
      ],
      "metadata": {
        "id": "xWr5-V4thU5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap awal pengambilan\n",
        "urllist = [\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-jazlyn-black-jazlyn-black-s?extParam=ivf%3Dfalse%26keyword%3Dbaju%26search_id%3D20250114050649233F63B3CB036A323GNH%26src%3Dsearch\",\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-gribson-rayon-navy-s\",\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-lavrenti-white-lavrenti-white-s\"\n",
        "]"
      ],
      "metadata": {
        "id": "kJea43wQk49U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan untuk proses pengambilan list\n",
        "def review_scrapper(url): #Fungsi ulasan\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "  #pelacakan ulasan\n",
        "  ulasan = []\n",
        "  for rev in soup.find_all('div', class_='review-class'):\n",
        "    teks = rev.find('div', class_='review-content').text.strip()\n",
        "    ulasan.append(teks)\n",
        "  return ulasan"
      ],
      "metadata": {
        "id": "_4GeAo7aGbx3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pengambilan nilai ulasan per potongan"
      ],
      "metadata": {
        "id": "alUWazR_J4vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fungsi pemotongan analisis\n",
        "def chunk_and_execute(urls, chunk_size=10):\n",
        "    totulas = []\n",
        "\n",
        "    def process_urls(chunk):\n",
        "        nonlocal totulas\n",
        "\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            results = executor.map(review_scrapper, chunk)\n",
        "\n",
        "        # Extend the main list with scraped data\n",
        "        for result in results:\n",
        "            totulas.extend(result)\n",
        "\n",
        "    num_chunks = int(len(urls) / chunk_size) + (len(urls) % chunk_size != 0)\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = min((i + 1) * chunk_size, len(urls))\n",
        "\n",
        "        chunk_url_list = urls[start_idx:end_idx]\n",
        "\n",
        "        process_urls(chunk_url_list)\n",
        "\n",
        "        # Penyimpanan hasil sementara\n",
        "        pd.DataFrame(totulas[:], columns=['Review']).to_csv('intermediate_reviews{}.csv'.format(i), index=False)\n",
        "\n",
        "    return totulas\n",
        "\n",
        "#ke tahap akhir"
      ],
      "metadata": {
        "id": "roVHgmd2JMl1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#penyatuan ke hasil akhir\n",
        "hslakhir = chunk_and_execute(urllist)\n",
        "#ke penyetelan data csv"
      ],
      "metadata": {
        "id": "YdXlCUiDrO6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "totulas adalah 'total ulasan'"
      ],
      "metadata": {
        "id": "zkt3ypzVJ2Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan df untuk pembersihan\n",
        "dfori = pd.DataFrame(hslakhir, columns=['Review'])\n",
        "dfkopi = dfori.copy() #Jangan pakai data asli\n",
        "dfkopi.to_csv('tokopedia_reviews.csv', index=False)"
      ],
      "metadata": {
        "id": "wi0e2dg7KS1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi dataset\n",
        "dfinfo = dfkopi.info()\n",
        "print(dfinfo)"
      ],
      "metadata": {
        "id": "tQkvoQdAK7y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tahap awal (pembersihan)"
      ],
      "metadata": {
        "id": "yd95Hc1KJktQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan untuk pembersihan\n"
      ],
      "metadata": {
        "id": "JNP_5d9vJjtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan tahap awal\n"
      ],
      "metadata": {
        "id": "NDIgOYfQIPdx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}