{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtiTaNRXmjXsjgxH/m0Z8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGkurnia/sentiment/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nama : Derfansyah Guswiranata Kurnia\n",
        "- Iddicoding: dgkurnia\n",
        "- email dicoding: weerakurnia@gmai.com"
      ],
      "metadata": {
        "id": "ZFgY-GaMMUMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Insiasi"
      ],
      "metadata": {
        "id": "I67moXBB9Kl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perpustakaan tahap awal\n",
        "!pip install selenium beautifulsoup4 pandas"
      ],
      "metadata": {
        "id": "8e3E8nEu9HDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411c1984-8d1b-4ec3-bdde-4eb1c6aac26e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.28.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Impor Bagian awal\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.webdriver import WebDriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "#modifikasi percepatan\n",
        "import asyncio\n",
        "import aiohttp\n",
        "from concurrent.futures import ProcessPoolExecutor"
      ],
      "metadata": {
        "id": "G0JFUIhxA7w8"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan pembuatan ulasan\n",
        "import requests  # Mengirim permintaan HTTP\n",
        "#mode' tanpa kepala'\n",
        "from selenium.webdriver.chrome.service import Service #layanan\n",
        "from selenium.webdriver.chrome.options import Options #pilihan"
      ],
      "metadata": {
        "id": "m1WaH1VJnoXK"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "nxlN2zGP8_fz"
      },
      "outputs": [],
      "source": [
        "#Next Import\n",
        "import datetime as dt  # Manipulasi data waktu dan tanggal\n",
        "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
        "import string  # Berisi konstanta string, seperti tanda baca\n",
        "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
        "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sastrawi"
      ],
      "metadata": {
        "id": "CthS3NbTETmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalasi sastrawi\n",
        "!pip install sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmP2sjmKgLXm",
        "outputId": "8a8faf43-a5f7-424a-baa9-414ce59b672b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Impor Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
        "#ke wordcloud"
      ],
      "metadata": {
        "id": "Cwad-u4jgN6b"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seksi wordcloud\n",
        "!pip install wordcloud\n",
        "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks\n",
        "# ke NITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iaIjWrHHPiA",
        "outputId": "1478c348-f086-4f29-e318-b592038a216a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wordcloud) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pembaruan rutin"
      ],
      "metadata": {
        "id": "9iVHMi35Ao_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pembaruan\n",
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou6BQbWPLODT",
        "outputId": "0b5e268d-1fe1-415b-9238-0c2ac8e71234"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Waiting for headers] [Connecting to r2u.stat.i\r                                                                                                    \rHit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chromedriver\n",
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6W-fld-LbCW",
        "outputId": "5a1f87da-82a8-4c45-a397-0377298dc3f7"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 55 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#impor file tambahan (google drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_1qYPLME9l8",
        "outputId": "82a29ecb-09a0-4bd2-d3db-0fc177e8afc1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perpustakaan lain untuk analisis"
      ],
      "metadata": {
        "id": "rFOBGavtLc-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Seksi Io dan lain-lain\n",
        "import os\n",
        "from io import StringIO\n",
        "import concurrent.futures #untuk pemrograman paralel\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "OJwYodA9Msss"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Interpolasi untuk perbaikan: Grafik\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "#perpustakaan untuk interpolasi\n",
        "from scipy.interpolate import interp1d"
      ],
      "metadata": {
        "id": "1F5B6x4IGCU4"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NITK\n",
        "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
        "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
        "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stopwords) dalam berbagai bahasa."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4LADjm8gWcQ",
        "outputId": "26e11068-b6a3-4c4c-8432-b953a84ce26c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian lain\n",
        "import csv\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "fjfVZi3GLg35"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persiapan untuk analisis"
      ],
      "metadata": {
        "id": "E98qlEH4M1DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pandas\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "d_YCBQfMmhQo"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ekstraksi\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer  #sentimen\n",
        "#pemisahan\n",
        "from sklearn.model_selection import train_test_split as ttsplit\n",
        "#ke klasifikasi"
      ],
      "metadata": {
        "id": "YX0Ag2T7MzVc"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#klasifikasi randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier as rfclasifi #teknik 'randomfprest'\n",
        "from sklearn.tree import DecisionTreeClassifier #teknik 'keputusan'\n",
        "from sklearn.svm import SVC #teknik SVC\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "piG-cutDNUEt"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pengambilan ulasan dari situs Tokopedia"
      ],
      "metadata": {
        "id": "xWr5-V4thU5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan sesi\n",
        "session = requests.Session()"
      ],
      "metadata": {
        "id": "2xlAEb1JOMVc"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap awal pengambilan\n",
        "urllist = [\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-jazlyn-black-jazlyn-black-s/review\",\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-gribson-rayon-navy-s/review\",\n",
        "    \"https://www.tokopedia.com/erigo/kemeja-unisex-erigo-short-shirt-lavrenti-white-lavrenti-white-s/review\"\n",
        "]"
      ],
      "metadata": {
        "id": "kJea43wQk49U"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ada tiga ulasan yang dipakai untuk analisis"
      ],
      "metadata": {
        "id": "louZK_TEEtni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan untuk proses pengambilan list: Tahap Extraksi HTM secara asinkronus\n",
        "async def fetch_html(url):\n",
        "    response = await asyncio.get_event_loop().run_in_executor(None, session.get, url)\n",
        "    response.raise_for_status()  # Penanda eror\n",
        "    return response.content\n",
        "#ke scrapping"
      ],
      "metadata": {
        "id": "_4GeAo7aGbx3"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proses utama 'ekstraksi'\n",
        "async def review_scrapper(url):\n",
        "    html_content = await fetch_html(url)\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # ekstraksi ulasan\n",
        "    results = []  # Bentuk awal\n",
        "    for rev in soup.find_all('div', class_='review-class'):\n",
        "        teks = rev.find('div', class_='review-content').text.strip()\n",
        "        results.append(teks)  # Proses ekstraksi\n",
        "    return results  # Return the list of reviews\n",
        "#ke persiapan url"
      ],
      "metadata": {
        "id": "3gaflRMkqW8c"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan asinkronus untuk pemrosesan url\n",
        "def process_urls(chunk):\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "\n",
        "    # Tugas asinkronus\n",
        "    tasks = [review_scrapper(url) for url in chunk]\n",
        "    results = loop.run_until_complete(asyncio.gather(*tasks))\n",
        "\n",
        "    # Pemerataan hasil\n",
        "    return [item for sublist in results for item in sublist]\n",
        "#ke fungsi utama"
      ],
      "metadata": {
        "id": "hg4DuheqmD82"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pengambilan nilai ulasan per potongan"
      ],
      "metadata": {
        "id": "alUWazR_J4vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fungsi pemotongan analisis\n",
        "def chunk_and_execute(urls, chunk_size=14, output_prefix='intermediate_reviews'):\n",
        "    checkpoint_file = f'{output_prefix}_checkpoint.txt'\n",
        "\n",
        "    # Penyimpanan ekstraksi\n",
        "    start_index = 0\n",
        "    if os.path.exists(checkpoint_file):\n",
        "        with open(checkpoint_file, 'r') as f:\n",
        "            start_index = int(f.read().strip())\n",
        "\n",
        "    with open(f'{output_prefix}_final.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Review']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        # Penulisan kepala\n",
        "        if start_index == 0:\n",
        "            writer.writeheader()\n",
        "\n",
        "        num_chunks = (len(urls) + chunk_size - 1) // chunk_size\n",
        "\n",
        "        with ProcessPoolExecutor(max_workers=10) as executor:\n",
        "            for i in range(start_index, num_chunks):\n",
        "                start_idx = i * chunk_size\n",
        "                end_idx = min((i + 1) * chunk_size, len(urls))\n",
        "\n",
        "                chunk_url_list = urls[start_idx:end_idx]\n",
        "                results = executor.submit(process_urls, chunk_url_list).result()\n",
        "\n",
        "                # Write each review to CSV file\n",
        "                for review in results:\n",
        "                    writer.writerow({'Review': review})\n",
        "\n",
        "                # Penyimpanan indeks\n",
        "                with open(checkpoint_file, 'w') as f:\n",
        "                    f.write(str(i + 1))  # Simpan indeks lain\n",
        "#ke eksekusi"
      ],
      "metadata": {
        "id": "roVHgmd2JMl1"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#penyatuan ke hasil akhir\n",
        "hslakhir = chunk_and_execute(urllist)\n",
        "#ke penyetelan data csv"
      ],
      "metadata": {
        "id": "YdXlCUiDrO6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "totulas adalah **'total ulasan'** yang dipakai untuk analisis hasi akhir **(hslakhir)**"
      ],
      "metadata": {
        "id": "zkt3ypzVJ2Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persiapan data-jadi\n",
        "Inspeksi hasil akhir"
      ],
      "metadata": {
        "id": "v9DdIJexDmgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#inspeksi hasil akhir\n",
        "print(hslakhir)"
      ],
      "metadata": {
        "id": "E3wpA_9T3zBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan df untuk pembersihan\n",
        "dfori = pd.DataFrame(hslakhir, columns=['Ulasan'])\n",
        "dfkopi = dfori.copy() #Jangan pakai data asli\n",
        "dfkopi.to_csv('tokopedia_reviews.csv', index=False)"
      ],
      "metadata": {
        "id": "wi0e2dg7KS1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data yang dipakai adala **'dfkopi'**"
      ],
      "metadata": {
        "id": "AGWfNanE574Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi dataset\n",
        "dfinfo = dfkopi.info()\n",
        "print(dfinfo)"
      ],
      "metadata": {
        "id": "tQkvoQdAK7y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tahap awal (pembersihan)"
      ],
      "metadata": {
        "id": "yd95Hc1KJktQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapan untuk pembersihan\n"
      ],
      "metadata": {
        "id": "JNP_5d9vJjtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan tahap awal\n"
      ],
      "metadata": {
        "id": "NDIgOYfQIPdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pembersihan tahap lanjut\n"
      ],
      "metadata": {
        "id": "8_h47LQ9fDcC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}